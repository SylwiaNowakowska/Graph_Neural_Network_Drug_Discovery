{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16SwHfblfESQBMHBdCKBWQjm0VZCxveBj","authorship_tag":"ABX9TyP4oORqI9NE0qgglEAw7CCn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Graph Neural Networks for Drug Discovery\n","\n","This project is inspired by DeepFindr GNN project: <br>\n","https://www.youtube.com/@DeepFindr/videos <br>\n","https://github.com/deepfindr/gnn-project"],"metadata":{"id":"4APNttty_oaI"}},{"cell_type":"markdown","source":["### Libraries' installation "],"metadata":{"id":"Od2ssGSTtdGf"}},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K01msh5Stk2c","executionInfo":{"status":"ok","timestamp":1670153609450,"user_tz":-60,"elapsed":449,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"c4fc0ccf-a1a4-4804-dc1f-83d9c2e178c6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.8.15\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKubWmSQtlgg","executionInfo":{"status":"ok","timestamp":1670157389239,"user_tz":-60,"elapsed":26870,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"35fe16c0-cb02-4c8e-ebe8-04d1cec04265"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 8.9 MB 2.7 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 2.6 MB/s \n","\u001b[K     |████████████████████████████████| 280 kB 5.0 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install rdkit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lkk4eBAqtoJh","executionInfo":{"status":"ok","timestamp":1670157396728,"user_tz":-60,"elapsed":7521,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"5ce77a42-4c0f-4de6-f070-f1f1638d2200"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rdkit\n","  Downloading rdkit-2022.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n","\u001b[K     |████████████████████████████████| 29.3 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2022.9.2\n"]}]},{"cell_type":"code","source":["!pip install deepchem==2.6.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kgfr7ShkNBHZ","executionInfo":{"status":"ok","timestamp":1670157408903,"user_tz":-60,"elapsed":12193,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"4aa16b89-4c1d-4819-d9a2-bae6bae906c9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deepchem==2.6.1\n","  Downloading deepchem-2.6.1-py3-none-any.whl (608 kB)\n","\u001b[K     |████████████████████████████████| 608 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem==2.6.1) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from deepchem==2.6.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem==2.6.1) (1.3.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem==2.6.1) (1.2.0)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem==2.6.1) (1.21.6)\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n","\u001b[K     |████████████████████████████████| 29.3 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem==2.6.1) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem==2.6.1) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem==2.6.1) (1.15.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi->deepchem==2.6.1) (7.1.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem==2.6.1) (3.1.0)\n","Installing collected packages: rdkit-pypi, deepchem\n","Successfully installed deepchem-2.6.1 rdkit-pypi-2022.9.2\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"cF0CNy3StzX-"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch_geometric\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.data import Dataset\n","\n","import rdkit\n","from rdkit import Chem\n","from rdkit.Chem import Draw\n","\n","import deepchem as dc\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","from tqdm import tqdm "],"metadata":{"id":"4BN8MRuPtyQ-","executionInfo":{"status":"ok","timestamp":1670157415307,"user_tz":-60,"elapsed":6432,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(f\"Torch version: {torch.__version__}\")\n","print(f\"Cuda available: {torch.cuda.is_available()}\")\n","print(f\"Torch geometric version: {torch_geometric.__version__}\")\n","print(f\"RDKit version: {rdkit.__version__}\")\n","print(f\"DeepChem version: {dc.__version__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zp7VYviiIsuA","executionInfo":{"status":"ok","timestamp":1670157668960,"user_tz":-60,"elapsed":8,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"24706b4f-f702-4fbb-d3d7-00b10043c71b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 1.12.1+cu113\n","Cuda available: False\n","Torch geometric version: 2.2.0\n","RDKit version: 2022.09.1\n","DeepChem version: 2.6.1\n"]}]},{"cell_type":"code","source":["# # mounting Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"C_baYSirOi4Q","executionInfo":{"status":"aborted","timestamp":1670153642710,"user_tz":-60,"elapsed":28,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Download / Loading"],"metadata":{"id":"EbsjCwWr1XXb"}},{"cell_type":"code","source":["dataset_path = '/content/drive/MyDrive/COLAB_NOTEBOOKS/Graph_Neural_Network_Drug_Discovery_HIV_Dataset'"],"metadata":{"id":"kex4h-Vk_GUJ","executionInfo":{"status":"ok","timestamp":1670157670750,"user_tz":-60,"elapsed":268,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["### Downloading the dataset with automatic creation of PyTorch Geometric in memory dataset\n","## The following line downloads and process the data - need to be run only once\n","#data = MoleculeNet(root=dataset_path, name='HIV')\n","\n","## Afterwards, the dataset can be loaded from the drive\n","#data_path = os.path.join(dataset_path, 'hiv/processed/data.pt')\n","#data = torch.load(data_path)"],"metadata":{"id":"vD-201NktxQu","executionInfo":{"status":"aborted","timestamp":1670153642712,"user_tz":-60,"elapsed":27,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wvldTpbjpbe5","executionInfo":{"status":"ok","timestamp":1670157680617,"user_tz":-60,"elapsed":1281,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"5401bce1-4eb6-41e1-9b6f-ca6d702fd569"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                              smiles activity  HIV_active\n","0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n","1  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n","2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n","3    Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n","4                             O=S(=O)(O)CCS(=O)(=O)O       CI           0"],"text/html":["\n","  <div id=\"df-5d7f9a75-c18d-47ba-b35a-e4017225c107\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>smiles</th>\n","      <th>activity</th>\n","      <th>HIV_active</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n","      <td>CI</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n","      <td>CI</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n","      <td>CI</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n","      <td>CI</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n","      <td>CI</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d7f9a75-c18d-47ba-b35a-e4017225c107')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5d7f9a75-c18d-47ba-b35a-e4017225c107 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5d7f9a75-c18d-47ba-b35a-e4017225c107');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# HIV CSV file\n","csv_path = os.path.join(dataset_path, 'hiv/raw/HIV.csv')\n","dataset_df = pd.read_csv(csv_path)\n","display(dataset_df.head())"]},{"cell_type":"code","source":["# from https://github.com/deepfindr/gnn-project/blob/main/dataset_featurizer.py\n","\n","class MoleculeDataset(Dataset):\n","    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n","        \"\"\"\n","        root = Where the dataset should be stored. This folder is split\n","        into raw_dir (downloaded dataset) and processed_dir (processed data). \n","        \"\"\"\n","        self.test = test\n","        self.filename = filename\n","        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n","        \n","    @property\n","    def raw_file_names(self):\n","        \"\"\" If this file exists in raw_dir, the download is not triggered.\n","            (The download func. is not implemented here)  \n","        \"\"\"\n","        return self.filename\n","\n","    @property\n","    def processed_file_names(self):\n","        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n","        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n","\n","        if self.test:\n","            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n","        else:\n","            return [f'data_{i}.pt' for i in list(self.data.index)]\n","        \n","\n","    def download(self):\n","        pass\n","\n","    def process(self):\n","        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n","        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n","        for index, row in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n","            # Featurize molecule\n","            mol = Chem.MolFromSmiles(row[\"smiles\"])\n","            f = featurizer._featurize(mol)\n","            data = f.to_pyg_graph()\n","            data.y = self._get_label(row[\"HIV_active\"])\n","            data.smiles = row[\"smiles\"]\n","            if self.test:\n","                torch.save(data, \n","                    os.path.join(self.processed_dir, \n","                                 f'data_test_{index}.pt'))\n","            else:\n","                torch.save(data, \n","                    os.path.join(self.processed_dir, \n","                                 f'data_{index}.pt'))\n","            \n","\n","    def _get_label(self, label):\n","        label = np.asarray([label])\n","        return torch.tensor(label, dtype=torch.int64)\n","\n","    def len(self):\n","        return self.data.shape[0]\n","\n","    def get(self, idx):\n","        \"\"\" - Equivalent to __getitem__ in pytorch\n","            - Is not needed for PyG's InMemoryDataset\n","        \"\"\"\n","        if self.test:\n","            data = torch.load(os.path.join(self.processed_dir, \n","                                 f'data_test_{idx}.pt'))\n","        else:\n","            data = torch.load(os.path.join(self.processed_dir, \n","                                 f'data_{idx}.pt'))        \n","        return data\n"],"metadata":{"id":"SIQO2HxQ75y1","executionInfo":{"status":"ok","timestamp":1670157686982,"user_tz":-60,"elapsed":350,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["molecule_data_path = os.path.join(dataset_path, 'hiv/')\n","dataset = MoleculeDataset(root=molecule_data_path, filename='HIV.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4kmGzsV752d","executionInfo":{"status":"ok","timestamp":1670158517019,"user_tz":-60,"elapsed":825971,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"48efc598-80c8-46a7-9718-8fc621243472"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing...\n","100%|██████████| 41127/41127 [13:31<00:00, 50.68it/s]\n","Done!\n"]}]},{"cell_type":"code","source":["print(dataset[0].edge_index.t())\n","print(dataset[0].x)\n","print(dataset[0].edge_attr)\n","print(dataset[0].y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjEPzE0q756E","executionInfo":{"status":"ok","timestamp":1670158544021,"user_tz":-60,"elapsed":424,"user":{"displayName":"Sylwia Nowakowska","userId":"00746351251013148788"}},"outputId":"b13adcb4-a747-4b11-8841-1936ef6a9bf5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0,  1],\n","        [ 1,  0],\n","        [ 1,  2],\n","        [ 2,  1],\n","        [ 2,  3],\n","        [ 3,  2],\n","        [ 3,  4],\n","        [ 4,  3],\n","        [ 4,  5],\n","        [ 5,  4],\n","        [ 5,  6],\n","        [ 6,  5],\n","        [ 6,  7],\n","        [ 7,  6],\n","        [ 7,  8],\n","        [ 8,  7],\n","        [ 6,  9],\n","        [ 9,  6],\n","        [ 4, 10],\n","        [10,  4],\n","        [10, 11],\n","        [11, 10],\n","        [11, 12],\n","        [12, 11],\n","        [12, 13],\n","        [13, 12],\n","        [11, 14],\n","        [14, 11],\n","        [14, 15],\n","        [15, 14],\n","        [15, 16],\n","        [16, 15],\n","        [16, 17],\n","        [17, 16],\n","        [15, 18],\n","        [18, 15],\n","        [ 9,  2],\n","        [ 2,  9],\n","        [18,  4],\n","        [ 4, 18]])\n","tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -3.,  0.,  0.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n","          0.,  0.],\n","        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n","          0.,  0.],\n","        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n","          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n","          0.,  0.]])\n","tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]])\n","tensor([0])\n"]}]},{"cell_type":"code","source":["## Oversampling of data oversample data.py"],"metadata":{"id":"KO_fE76p759z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### from https://github.com/deepfindr/gnn-project/blob/main/train.py\n","## get model\n","import torch\n","import torch.nn.functional as F \n","from torch.nn import Linear, BatchNorm1d, ModuleList\n","from torch_geometric.nn import TransformerConv, TopKPooling \n","from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n","torch.manual_seed(42)\n","\n","class GNN(torch.nn.Module):\n","    def __init__(self, feature_size, model_params):\n","        super(GNN, self).__init__()\n","        embedding_size = model_params[\"model_embedding_size\"]\n","        n_heads = model_params[\"model_attention_heads\"]\n","        self.n_layers = model_params[\"model_layers\"]\n","        dropout_rate = model_params[\"model_dropout_rate\"]\n","        top_k_ratio = model_params[\"model_top_k_ratio\"]\n","        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n","        dense_neurons = model_params[\"model_dense_neurons\"]\n","        edge_dim = model_params[\"model_edge_dim\"]\n","\n","        self.conv_layers = ModuleList([])\n","        self.transf_layers = ModuleList([])\n","        self.pooling_layers = ModuleList([])\n","        self.bn_layers = ModuleList([])\n","\n","        # Transformation layer\n","        self.conv1 = TransformerConv(feature_size, \n","                                    embedding_size, \n","                                    heads=n_heads, \n","                                    dropout=dropout_rate,\n","                                    edge_dim=edge_dim,\n","                                    beta=True) \n","\n","        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n","        self.bn1 = BatchNorm1d(embedding_size)\n","\n","        # Other layers\n","        for i in range(self.n_layers):\n","            self.conv_layers.append(TransformerConv(embedding_size, \n","                                                    embedding_size, \n","                                                    heads=n_heads, \n","                                                    dropout=dropout_rate,\n","                                                    edge_dim=edge_dim,\n","                                                    beta=True))\n","\n","            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n","            self.bn_layers.append(BatchNorm1d(embedding_size))\n","            if i % self.top_k_every_n == 0:\n","                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n","            \n","\n","        # Linear layers\n","        self.linear1 = Linear(embedding_size*2, dense_neurons)\n","        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n","        self.linear3 = Linear(int(dense_neurons/2), 1)  \n","\n","    def forward(self, x, edge_attr, edge_index, batch_index):\n","        # Initial transformation\n","        x = self.conv1(x, edge_index, edge_attr)\n","        x = torch.relu(self.transf1(x))\n","        x = self.bn1(x)\n","\n","        # Holds the intermediate graph representations\n","        global_representation = []\n","\n","        for i in range(self.n_layers):\n","            x = self.conv_layers[i](x, edge_index, edge_attr)\n","            x = torch.relu(self.transf_layers[i](x))\n","            x = self.bn_layers[i](x)\n","            # Always aggregate last layer\n","            if i % self.top_k_every_n == 0 or i == self.n_layers:\n","                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n","                    x, edge_index, edge_attr, batch_index\n","                    )\n","                # Add current representation\n","                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n","    \n","        x = sum(global_representation)\n","\n","        # Output block\n","        x = torch.relu(self.linear1(x))\n","        x = F.dropout(x, p=0.8, training=self.training)\n","        x = torch.relu(self.linear2(x))\n","        x = F.dropout(x, p=0.8, training=self.training)\n","        x = self.linear3(x)\n","\n","        return "],"metadata":{"id":"2FTcYbtV76BU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JABMxut876E9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JU6rD1Mlz229"},"execution_count":null,"outputs":[]}]}